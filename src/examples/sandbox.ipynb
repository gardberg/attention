{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import attention\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 32)\n",
      "(3, 2)\n",
      "(2, 3, 32)\n",
      "(3, 2, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "context_len = 3\n",
    "batch_size = 2\n",
    "emb_size = 32\n",
    "n_heads = 1\n",
    "d_k = emb_size // n_heads\n",
    "\n",
    "z = jnp.array(np.random.normal(size=(context_len, batch_size, emb_size)))\n",
    "print(z.shape)\n",
    "print(z.shape[:-1])\n",
    "v = z.transpose(1, 0, 2)\n",
    "print(v.shape)\n",
    "\n",
    "preattn = PreAttention(emb_size=emb_size, n_heads=n_heads, d_k=d_k, bias=False)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = preattn.init_state(rng)\n",
    "\n",
    "q = preattn(state, z)\n",
    "print(q.shape)\n",
    "\n",
    "# scores borde vara (3, 3, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "s = jnp.einsum('ibhd,jbhd->ijbh', q, q)\n",
    "print(s.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 1, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.matmul(q, jnp.transpose(q, axes=(0, 1, 3, 2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2, 1])\n",
      "(3, 3, 2, 1)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "qt = torch.randn(size=(context_len, batch_size, n_heads, d_k))\n",
    "kt = torch.randn(size=(context_len, batch_size, n_heads, d_k))\n",
    "\n",
    "qt_1 = torch.einsum('ibhd,jbhd->ijbh', qt, kt)\n",
    "print(qt_1.shape)\n",
    "\n",
    "qt_2 = jnp.einsum('ibhd,jbhd->ijbh', qt.detach().numpy(), kt.detach().numpy(), optimize='optimal')\n",
    "print(qt_2.shape)\n",
    "\n",
    "allclose = np.allclose(qt_1.detach().numpy(), qt_2)\n",
    "print(allclose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtj = qt.detach().numpy()\n",
    "ktj = kt.detach().numpy()\n",
    "\n",
    "res = jnp.einsum(\"...id,...jd->...ij\", qtj, ktj)\n",
    "print(res.shape)\n",
    "\n",
    "# Example 2: do the same operation using matmul\n",
    "\n",
    "res2 = jnp.matmul(qtj, ktj.transpose(0, 1, 3, 2))\n",
    "\n",
    "print(res2.shape)\n",
    "\n",
    "allclose = np.allclose(res, res2)\n",
    "print(allclose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = jnp.einsum(\"cbhd,Cbhd->cCbh\", qtj, ktj)\n",
    "print(res3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing a matrix is just dimension permutation\n",
    "\n",
    "x = np.random.normal(size=(2, 3))\n",
    "print(x)\n",
    "print(x.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.normal(size=(1, 3))\n",
    "jnp.einsum('ij,kj->ik', x, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=(2, 2))\n",
    "# Matrix matrix\n",
    "print(jnp.einsum('ij,kj->ik', x, x))\n",
    "print(x @ x.T)\n",
    "print(jnp.einsum('ik,kj->ij', x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention import softmax\n",
    "r = 0\n",
    "x = np.random.normal(size=(2, 2))\n",
    "print(x)\n",
    "xs = softmax(x, dim=r)\n",
    "print(xs)\n",
    "print(sum(xs, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
